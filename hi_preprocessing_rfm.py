{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh55K2pXflJfHqqcMAeEUD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnAWwgHta1lG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def data_preprocessing(marketing_info, onlinesales_info, customer_info, discount_info):\n",
        "  # 마케팅비용 = 오프라인비용 + 온라인비용\n",
        "  marketing_info['마케팅비용'] = marketing_info['오프라인비용'] + marketing_info['온라인비용']\n",
        "\n",
        "  # 총구매금액 = 수량 * 평균금액\n",
        "  onlinesales_info['총구매금액'] = onlinesales_info['수량'] * onlinesales_info['평균금액']\n",
        "\n",
        "  # 쿠폰상태 1: 사용, 0: 나머지\n",
        "  onlinesales_info['쿠폰상태'] = onlinesales_info['쿠폰상태'].map({'Used': 1, 'Not Used': 0, 'Clicked': 0})\n",
        "\n",
        "  # 고객지역: Chicago = 1, California = 2, New York = 3, New Jersey = 4, Washington DC = 5\n",
        "  region_mapping = {'Chicago': 1, 'California': 2, 'New York': 3, 'New Jersey': 4, 'Washington DC': 5}\n",
        "  customer_info['고객지역'] = customer_info['고객지역'].map(region_mapping)\n",
        "\n",
        "  # 남자 = 1, 여자 = 0\n",
        "  customer_info['성별'] = customer_info['성별'].map({'남': 1, '여': 0})\n",
        "\n",
        "  # 고객정보, 할인정보, 마케팅정보, 온라인판매정보 병합\n",
        "  data = pd.merge(customer_info, onlinesales_info, on='고객ID')\n",
        "\n",
        "  marketing_info = marketing_info.rename(columns = {\"날짜\" : \"거래날짜\"})\n",
        "  data = pd.merge(data, marketing_info, on='거래날짜')\n",
        "\n",
        "  data['월'] = pd.to_datetime(data['거래날짜']).dt.month\n",
        "  month_mapping = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
        "  discount_info['월'] = discount_info['월'].map(month_mapping)\n",
        "  data = pd.merge(data, discount_info, on=['월', '제품카테고리'])\n",
        "  data = data.drop(['월', '쿠폰코드'], axis = 1)\n",
        "\n",
        "\n",
        "  # 필요없는 문자 제거\n",
        "  data['고객ID'] = data['고객ID'].str.replace(\"USER_\", \"\")\n",
        "  data['거래ID'] = data['거래ID'].str.replace(\"Transaction_\", \"\")\n",
        "  data['제품ID'] = data['제품ID'].str.replace(\"Product_\", \"\")\n",
        "\n",
        "  # integer to string\n",
        "  data = data.astype({\"성별\": 'str', \"고객지역\": 'str', \"쿠폰상태\": 'str', \"할인율\": 'str'})\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "\n",
        "def marketing_preprocessing(data, marketing_info):\n",
        "  # 마케팅비용 = 오프라인비용 + 온라인비용\n",
        "  marketing_info['마케팅비용'] = marketing_info['오프라인비용'] + marketing_info['온라인비용']\n",
        "  marketing_info = marketing_info.rename(columns = {\"날짜\" : \"거래날짜\"})\n",
        "  data = pd.merge(data, marketing_info, on='거래날짜')\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "def rfm_data(data):\n",
        "  # 거래날짜를 datetime 형태로 변환\n",
        "  data['거래날짜'] = pd.to_datetime(data['거래날짜'])\n",
        "  data['총구매금액'] = data['수량'] * data['평균금액']\n",
        "  data['고객ID'] = data['고객ID'].str.replace(\"USER_\", \"\")\n",
        "  data['성별'] = data['성별'].str.replace(\"남\", \"1\").str.replace(\"여\", \"0\")\n",
        "  data['거래ID'] = data['거래ID'].str.replace(\"Transaction_\", \"\")\n",
        "  data['제품ID'] = data['제품ID'].str.replace(\"Product_\", \"\")\n",
        "  #region_mapping = {'Chicago': 1, 'California': 2, 'New York': 3, 'New Jersey': 4, 'Washington DC': 5}\n",
        "  #data['고객지역'] = data['고객지역'].map(region_mapping)\n",
        "  data = data.astype({\"성별\": 'str', \"고객지역\": 'str', \"거래ID\": 'str', \"제품ID\": 'str'})\n",
        "\n",
        "  # RFM 데이터 생성\n",
        "  rfm_data = data.groupby('고객ID').agg({\n",
        "      '거래날짜': lambda x: (data['거래날짜'].max() - x.max()).days,\n",
        "      '거래ID': 'nunique',\n",
        "      '총구매금액': 'sum'\n",
        "      }).rename(columns={'거래날짜': 'Recency', '거래ID': 'Frequency', '총구매금액': 'MonetaryValue'})\n",
        "  rfm_data.reset_index(inplace=True)\n",
        "  rfm_data = pd.merge(rfm_data, data, on='고객ID')\n",
        "\n",
        "\n",
        "  return rfm_data\n",
        "\n",
        "\n",
        "\n",
        "class numeric_filtering(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, check_const_col=True, check_id_col=True):\n",
        "        self.check_const_col = check_const_col\n",
        "        self.check_id_col = check_id_col\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if self.check_const_col:\n",
        "            self.constant_col = [i for i in range(X.shape[1]) if X[:,i].std() == 0]\n",
        "        else:\n",
        "            self.constant_col = []\n",
        "\n",
        "        if self.check_id_col:\n",
        "            self.id_col = [i for i in range(X.shape[1]) if len(np.unique(np.diff(X[:,i]))) == 1]\n",
        "        else:\n",
        "            self.id_col = []\n",
        "\n",
        "        self.rm_cols = self.constant_col + self.id_col\n",
        "        self.final_cols = [i for i in range(X.shape[1]) if i not in self.rm_cols]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[:, self.final_cols]\n",
        "\n",
        "class categorical_filtering(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, check_const_col=True, check_id_col=True, check_cardinality=True):\n",
        "        self.check_const_col = check_const_col\n",
        "        self.check_id_col = check_id_col\n",
        "        self.check_cardinality = check_cardinality\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if self.check_const_col:\n",
        "            self.constant_col = [i for i in range(X.shape[1]) if len(np.unique(X[:,i])) == 1]\n",
        "        else:\n",
        "            self.constant_col = []\n",
        "\n",
        "        if self.check_id_col:\n",
        "            self.id_col = [i for i in range(X.shape[1]) if len(np.unique(X[:,i])) == X.shape[0]]\n",
        "        else:\n",
        "            self.id_col = []\n",
        "\n",
        "        if self.check_cardinality:\n",
        "            self.cardinality = [i for i in range(X.shape[1]) if len(np.unique(X[:,i])) > 50]\n",
        "        else:\n",
        "            self.cardinality = []\n",
        "\n",
        "        self.rm_cols = self.constant_col + self.id_col + self.cardinality\n",
        "        self.final_cols = [i for i in range(X.shape[1]) if i not in self.rm_cols]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[:, self.final_cols]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class RFMClusteringPipeline:\n",
        "    def __init__(self):\n",
        "        self.pipeline = self.create_pipeline()\n",
        "        self.rfm_scaled = None\n",
        "        self.optimal_clusters = None\n",
        "        self.kmeans_model = None\n",
        "\n",
        "    def create_pipeline(self):\n",
        "        num_pipeline = Pipeline(steps=[\n",
        "            ('step1',   SimpleImputer(strategy=\"mean\") ),\n",
        "            ('step2',   numeric_filtering()  ),\n",
        "            ('step3',   StandardScaler()  ),\n",
        "        ])\n",
        "\n",
        "        cat_pipeline = Pipeline(steps=[\n",
        "            ('step1',   SimpleImputer(strategy=\"most_frequent\") ),\n",
        "            ('step2',   categorical_filtering()  ),\n",
        "            ('step3',   OneHotEncoder()  ),\n",
        "        ])\n",
        "\n",
        "        transformer = ColumnTransformer(transformers=[\n",
        "            ('num', num_pipeline, make_column_selector(dtype_include=np.number)),\n",
        "            ('cat', cat_pipeline, make_column_selector(dtype_exclude=np.number))\n",
        "        ])\n",
        "\n",
        "        return transformer\n",
        "\n",
        "    def fit_transform(self, X):\n",
        "        self.pipeline.fit(X[['Recency', 'Frequency', 'MonetaryValue']])\n",
        "        self.rfm_scaled = self.pipeline.transform(X[['Recency', 'Frequency', 'MonetaryValue']])\n",
        "        return self.rfm_scaled\n",
        "\n",
        "    def elbow_method(self):\n",
        "        sse = {}\n",
        "        for k in range(1, 11):\n",
        "            kmeans = KMeans(n_clusters=k, random_state=1)\n",
        "            kmeans.fit(self.rfm_scaled)\n",
        "            sse[k] = kmeans.inertia_\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(list(sse.keys()), list(sse.values()), marker='o')\n",
        "        plt.xlabel(\"Number of clusters\")\n",
        "        plt.ylabel(\"SSE\")\n",
        "        plt.title(\"Elbow Method for Optimal Clusters\")\n",
        "        plt.show()\n",
        "\n",
        "        return self.find_elbow_point(sse)\n",
        "\n",
        "    def find_elbow_point(self, sse):\n",
        "        keys = list(sse.keys())\n",
        "        for i in range(len(keys) - 1):\n",
        "            value1 = sse[keys[i]]\n",
        "            value2 = sse[keys[i + 1]]\n",
        "            if abs(value1 - value2) >= 250:\n",
        "                return keys[i + 1]\n",
        "        return keys[-1]\n",
        "\n",
        "    def silhouette_method(self):\n",
        "        silhouette_scores = {}\n",
        "        for k in range(3, 8):\n",
        "            kmeans = KMeans(n_clusters=k, random_state=1)\n",
        "            kmeans.fit(self.rfm_scaled)\n",
        "            score = silhouette_score(self.rfm_scaled, kmeans.labels_)\n",
        "            silhouette_scores[k] = score\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(list(silhouette_scores.keys()), list(silhouette_scores.values()), marker='o')\n",
        "        plt.xlabel(\"Number of clusters\")\n",
        "        plt.ylabel(\"Silhouette Score\")\n",
        "        plt.title(\"Silhouette Scores for Different Number of Clusters\")\n",
        "        plt.show()\n",
        "\n",
        "        return max(silhouette_scores, key=silhouette_scores.get)\n",
        "\n",
        "    def fit_kmeans(self, method='silhouette'):\n",
        "        if self.rfm_scaled is None:\n",
        "            raise ValueError(\"Data has not been fit and transformed. Call fit_transform first.\")\n",
        "\n",
        "        if method == 'silhouette':\n",
        "            self.optimal_clusters = self.silhouette_method()\n",
        "        elif method == 'elbow':\n",
        "            self.optimal_clusters = self.elbow_method()\n",
        "        else:\n",
        "            raise ValueError(\"Invalid method. Choose 'silhouette' or 'elbow'.\")\n",
        "\n",
        "        self.kmeans_model = KMeans(n_clusters=self.optimal_clusters, random_state=1)\n",
        "        clusters = self.kmeans_model.fit_predict(self.rfm_scaled)\n",
        "        return clusters\n",
        "\n",
        "\n",
        "def add_cluster(data, clusters, on = '고객ID'):\n",
        "  clusters = clusters[['고객ID', 'Cluster']]\n",
        "  data = pd.merge(data, clusters, on=on)\n",
        "  return data\n",
        "\n",
        "\n",
        "# Usage:\n",
        "# rfm_data = rfm_data(ecommerce_df)\n",
        "# rfm_pipeline = RFMClusteringPipeline()\n",
        "# rfm_scaled = rfm_pipeline.fit_transform(rfm_data)\n",
        "# rfm_data['Cluster'] = rfm_pipeline.fit_kmeans(method='silhouette')\n",
        "# print(rfm_data.head())\n",
        "\n"
      ]
    }
  ]
}